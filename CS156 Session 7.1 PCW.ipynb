{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS156 Session 7.1 PCW.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGCo2Hy57aMR5j3yVe4Gk8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyGr6tffZ6nN",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNcF58dZRko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3140b4c5-3743-4841-e6b0-f327d61a82d8"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "np.random.seed(1234)\n",
        "\n",
        "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})\n",
        "\n",
        "from IPython.display import Image\n",
        "from numpy.core.umath_tests import matrix_multiply as mm\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import bernoulli, binom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaD9ZFhDaLNx",
        "colab_type": "text"
      },
      "source": [
        "# **Solving for Complete Likelihood**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHDICVFyZZRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neg_loglik(thetas, n, xs, zs):\n",
        "    return -np.sum([binom(n, thetas[z]).logpmf(x) for (x, z) in zip(xs, zs)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2k5Ee4RZctR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "34d242ab-e137-44ef-eba2-d6b1130f87d7"
      },
      "source": [
        "# setting initial parameters for mean and standard deviation\n",
        "m = 10\n",
        "theta_A = 0.8\n",
        "theta_B = 0.3\n",
        "theta_0 = [theta_A, theta_B]\n",
        "\n",
        "# conducting bernoulli trials for both coins\n",
        "coin_A = bernoulli(theta_A)\n",
        "coin_B = bernoulli(theta_B)\n",
        "\n",
        "# create dataset for coin tosses\n",
        "xs = map(sum, [coin_A.rvs(m), coin_A.rvs(m), coin_B.rvs(m), coin_A.rvs(m), coin_B.rvs(m)])\n",
        "\n",
        "# here we have the complete information of which coins were tossed\n",
        "zs = [0, 0, 1, 0, 1]\n",
        "\n",
        "bnds = [(0,1), (0,1)]\n",
        "minimize(neg_loglik, [0.5, 0.5], args=(m, xs, zs),\n",
        "         bounds=bnds, method='tnc', options={'maxiter': 100})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: -0.0\n",
              "     jac: array([0.000, 0.000])\n",
              " message: 'Local minimum reached (|pg| ~= 0)'\n",
              "    nfev: 1\n",
              "     nit: 0\n",
              "  status: 0\n",
              " success: True\n",
              "       x: array([0.500, 0.500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMbE_6SabCy",
        "colab_type": "text"
      },
      "source": [
        "# **Extrapolating the solution to solve for an incomplete likelihood**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbWOJR7TagkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "88497bb4-f938-40ab-c273-57a2a78f2a3b"
      },
      "source": [
        "heads = [14, 33, 19, 10, 0, 17, 24, 17, 1, 36, 5, 6, 5, 13, 4, 35, 5, 5, 74, 34]\n",
        "throws = [41, 43, 23, 23, 1, 23, 36, 37, 2, 131, 5, 29, 13, 47, 10, 58, 15, 14, 100, 113]\n",
        "\n",
        "arr = []\n",
        "for i in range(len(heads)):\n",
        "    arr.append((heads[i], throws[i]))\n",
        "\n",
        "xs = np.array(arr)\n",
        "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
        "\n",
        "tol = 0.01\n",
        "max_iter = 100\n",
        "\n",
        "ll_old = 0\n",
        "for i in range(max_iter):\n",
        "    ws_A = []\n",
        "    ws_B = []\n",
        "\n",
        "    vs_A = []\n",
        "    vs_B = []\n",
        "\n",
        "    ll_new = 0\n",
        "\n",
        "    # E-step: calculate probability distributions over possible completions\n",
        "    for x in xs:\n",
        "\n",
        "        # multinomial (binomial) log likelihood\n",
        "        ll_A = np.sum([x*np.log(thetas[0])])\n",
        "        ll_B = np.sum([x*np.log(thetas[1])])\n",
        "\n",
        "        # [EQN 1]\n",
        "        denom = np.exp(ll_A) + np.exp(ll_B)\n",
        "        w_A = np.exp(ll_A)/denom\n",
        "        w_B = np.exp(ll_B)/denom\n",
        "\n",
        "        ws_A.append(w_A)\n",
        "        ws_B.append(w_B)\n",
        "\n",
        "        # used for calculating theta\n",
        "        vs_A.append(np.dot(w_A, x))\n",
        "        vs_B.append(np.dot(w_B, x))\n",
        "\n",
        "        # update complete log likelihood\n",
        "        ll_new += w_A * ll_A + w_B * ll_B\n",
        "\n",
        "    # M-step: update values for parameters given current distribution\n",
        "    # [EQN 2]\n",
        "    thetas[0] = np.sum(vs_A, 0)/np.sum(vs_A)\n",
        "    thetas[1] = np.sum(vs_B, 0)/np.sum(vs_B)\n",
        "    # print distribution of z for each x and current parameter estimate\n",
        "\n",
        "    print(\"Iteration: %d\" % (i+1))\n",
        "    print(\"theta_A = %.2f, theta_B = %.2f, ll = %.2f\" % (thetas[0,0], thetas[1,0], ll_new))\n",
        "\n",
        "    if np.abs(ll_new - ll_old) < tol:\n",
        "        break\n",
        "    ll_old = ll_new"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1\n",
            "theta_A = 0.38, theta_B = 0.32, ll = -779.13\n",
            "Iteration: 2\n",
            "theta_A = 0.39, theta_B = 0.26, ll = -694.84\n",
            "Iteration: 3\n",
            "theta_A = 0.40, theta_B = 0.24, ll = -684.80\n",
            "Iteration: 4\n",
            "theta_A = 0.40, theta_B = 0.24, ll = -683.44\n",
            "Iteration: 5\n",
            "theta_A = 0.40, theta_B = 0.24, ll = -683.37\n",
            "Iteration: 6\n",
            "theta_A = 0.40, theta_B = 0.24, ll = -683.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUrPNWysKNb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code adapted from https://people.duke.edu/~ccc14/sta-663/EMAlgorithm.html\n",
        "\n",
        "def em(xs, thetas, max_iter=100, tol=1e-6):\n",
        "    \"\"\"Expectation-maximization for coin sample problem.\"\"\"\n",
        "\n",
        "    ll_old = -np.infty\n",
        "    for i in range(max_iter):\n",
        "        ll = np.array([np.sum(xs * np.log(theta), axis=1) for theta in thetas])\n",
        "        lik = np.exp(ll)\n",
        "        ws = lik/lik.sum(0)\n",
        "        vs = np.array([w[:, None] * xs for w in ws])\n",
        "        thetas = np.array([v.sum(0)/v.sum() for v in vs])\n",
        "        ll_new = np.sum([w*l for w, l in zip(ws, ll)])\n",
        "        if np.abs(ll_new - ll_old) < tol:\n",
        "            break\n",
        "        ll_old = ll_new\n",
        "    return i, thetas, ll_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyDgSq7HZQ8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fe79bbe1-3494-4a17-94a6-33356da0ab58"
      },
      "source": [
        "xs = np.array(arr)\n",
        "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
        "\n",
        "#run the EM function\n",
        "i, thetas, ll = em(xs, thetas)\n",
        "print(i)\n",
        "for theta in thetas:\n",
        "    print(theta)\n",
        "print(ll)\n",
        "np.random.seed(111)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "[0.401 0.599]\n",
            "[0.235 0.765]\n",
            "-683.3671795030095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFsnRfLzc9b4",
        "colab_type": "text"
      },
      "source": [
        "Here, we notice that we get the same results by using the EM algorithm as we did in the expanded method above."
      ]
    }
  ]
}